{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "C1_W3_Lab_2_exploring_convolutions.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/https-deeplearning-ai/tensorflow-1-public/blob/25_august_2021_fixes/C1/W3/ungraded_labs/C1_W3_Lab_2_exploring_convolutions.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "tJTHvE8Qe5nM"
      },
      "source": [
        "Let's explore how convolutions work by creating a basic convolution on a 2D Grey Scale image. First we can load the image by taking the 'ascent' image from scipy. It's a nice, built-in picture with lots of angles and lines. "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DZ5OXYiolCUi"
      },
      "source": [
        "import cv2\n",
        "import numpy as np\n",
        "from scipy import misc\n",
        "i = misc.ascent()\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "SRIzxjWWfJjk"
      },
      "source": [
        "Next, we can use the pyplot library to draw the image so we know what it looks like."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "R4p0cfWcfIvi"
      },
      "source": [
        "import matplotlib.pyplot as plt\n",
        "plt.grid(False)\n",
        "plt.gray()\n",
        "plt.axis('off')\n",
        "plt.imshow(i)\n",
        "plt.show()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "C1mhZ_ZTfPWH"
      },
      "source": [
        "The image is stored as a numpy array, so we can create the transformed image by just copying that array. Let's also get the dimensions of the image so we can loop over it later. "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "o5pxGq1SmJMD"
      },
      "source": [
        "i_transformed = np.copy(i)\n",
        "size_x = i_transformed.shape[0]\n",
        "size_y = i_transformed.shape[1]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Y7PwNkiXfddd"
      },
      "source": [
        "Now we can create a filter as a 3x3 array. "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "sN3imZannN5J"
      },
      "source": [
        "# This filter detects edges nicely\n",
        "# It creates a convolution that only passes through sharp edges and straight\n",
        "# lines.\n",
        "\n",
        "#Experiment with different values for fun effects.\n",
        "#filter = [ [0, 1, 0], [1, -4, 1], [0, 1, 0]]\n",
        "\n",
        "# A couple more filters to try for fun!\n",
        "filter = [ [-1, -2, -1], [0, 0, 0], [1, 2, 1]]\n",
        "#filter = [ [-1, 0, 1], [-2, 0, 2], [-1, 0, 1]]\n",
        "\n",
        "# If all the digits in the filter don't add up to 0 or 1, you \n",
        "# should probably do a weight to get it to do so\n",
        "# so, for example, if your weights are 1,1,1 1,2,1 1,1,1\n",
        "# They add up to 10, so you would set a weight of .1 if you want to normalize them\n",
        "weight  = 1"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "JQmm_iBufmCz"
      },
      "source": [
        "Now let's create a convolution. We will iterate over the image, leaving a 1 pixel margin, and multiply out each of the neighbors of the current pixel by the value defined in the filter. \n",
        "\n",
        "i.e. the current pixel's neighbor above it and to the left will be multiplied by the top left item in the filter etc. etc. We'll then multiply the result by the weight, and then ensure the result is in the range 0-255\n",
        "\n",
        "Finally we'll load the new value into the transformed image. "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "299uU2jAr90h"
      },
      "source": [
        "for x in range(1,size_x-1):\n",
        "  for y in range(1,size_y-1):\n",
        "      convolution = 0.0\n",
        "      convolution = convolution + (i[x-1, y-1] * filter[0][0])\n",
        "      convolution = convolution + (i[x-1, y] * filter[0][1])  \n",
        "      convolution = convolution + (i[x-1. y+1] * filter[0][2])     \n",
        "      convolution = convolution + (i[x, y-1] * filter[1][0])    \n",
        "      convolution = convolution + (i[x, y] * filter[1][1])    \n",
        "      convolution = convolution + (i[x, y+1] * filter[1][2])    \n",
        "      convolution = convolution + (i[x+1, y-1] * filter[2][0])    \n",
        "      convolution = convolution + (i[x+1, y] * filter[2][1])    \n",
        "      convolution = convolution + (i[x+1, y+1] * filter[2][2])    \n",
        "      convolution = convolution * weight   \n",
        "      if(convolution<0):\n",
        "        convolution=0\n",
        "      if(convolution>255):\n",
        "        convolution=255\n",
        "      i_transformed[x, y] = convolution"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6XA--vgvgDEQ"
      },
      "source": [
        "Now we can plot the image to see the effect of the convolution!"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7oPhUPNhuGWC"
      },
      "source": [
        "# Plot the image. Note the size of the axes -- they are 512 by 512\n",
        "plt.gray()\n",
        "plt.grid(False)\n",
        "plt.imshow(i_transformed)\n",
        "#plt.axis('off')\n",
        "plt.show()   "
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xF0FPplsgHNh"
      },
      "source": [
        "This code will show a (2, 2) pooling. The idea here is to iterate over the image, and look at the pixel and it's immediate neighbors to the right, beneath, and right-beneath. Take the largest of them and load it into the new image. Thus the new image will be 1/4 the size of the old -- with the dimensions on X and Y being halved by this process. You'll see that the features get maintained despite this compression!"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kDHjf-ehaBqm"
      },
      "source": [
        "new_x = int(size_x/2)\n",
        "new_y = int(size_y/2)\n",
        "newImage = np.zeros((new_x, new_y))\n",
        "for x in range(0, size_x, 2):\n",
        "  for y in range(0, size_y, 2):\n",
        "    pixels = []\n",
        "    pixels.append(i_transformed[x, y])\n",
        "    pixels.append(i_transformed[x+1, y])\n",
        "    pixels.append(i_transformed[x, y+1])\n",
        "    pixels.append(i_transformed[x+1, y+1])\n",
        "    newImage[int(x/2),int(y/2)] = max(pixels)\n",
        "\n",
        "# Plot the image. Note the size of the axes -- now 256 pixels instead of 512\n",
        "plt.gray()\n",
        "plt.grid(False)\n",
        "plt.imshow(newImage)\n",
        "#plt.axis('off')\n",
        "plt.show()      \n",
        "    \n",
        "    "
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}